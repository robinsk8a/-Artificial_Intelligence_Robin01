{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e8ab786-e4fe-4cdb-8124-ac1a91b92506",
   "metadata": {},
   "source": [
    "These are some notes from the Daniel Bourke's \"Learn PyTorch for deep learning in a day. Literally.\" YouTube course.\n",
    "Link: https://www.youtube.com/watch?v=Z_ikDlimN6A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1286e4f1-43fc-4770-8eed-477d17672369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pandas) (1.24.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pandas) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (3.6.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.19 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (1.24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: torch in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (1.8.1)\n",
      "Requirement already satisfied: typing-extensions in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: numpy in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (1.24.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eeecd453-84ff-46a0-a758-5b09457914ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.1+cu102\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "207471b9-06a4-41e4-8032-3fac5ec902fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch ternsor are usually created using the pytorch buildin function\n",
    "# \"torch.Tensor\"\n",
    "scalar = torch.tensor(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d1efbf0-82f1-4774-b9ba-5b3c1ab5a5ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fee976f6-b95b-4226-bf46-6f94a903db4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get tensor back as python int\n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b339254-51b1-428b-bad5-a25ae9a7a033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = torch.tensor([7,7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d955e512-e8bb-46d0-b704-f05ee1a395ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c58da263-f5a8-441e-a229-97d3a3c17bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b6e9d24-f7b9-4f2b-8738-7a06a42582cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7, 8],\n",
       "        [8, 9]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MATRIX\n",
    "MATRIX = torch.tensor([[7,8], [8,9]])\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79b75580-5b25-4927-bb62-57f3aabba5ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f569901e-00ad-420e-af49-897dbe4dd082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef0c9003-993d-44b4-9266-bcd2d6fb0223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 3, 5],\n",
       "         [5, 2, 6],\n",
       "         [6, 7, 9]],\n",
       "\n",
       "        [[1, 3, 5],\n",
       "         [5, 2, 6],\n",
       "         [6, 7, 9]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TENSOR\n",
    "TENSOR = torch.tensor([[[1,3,5],\n",
    "                       [5,2,6],\n",
    "                       [6,7,9]],\n",
    "                       [[1,3,5],\n",
    "                       [5,2,6],\n",
    "                       [6,7,9]]])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4aebe784-8639-46b3-856d-da4dac00d75e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2119167-83cd-4f73-9ab3-37c9b5cced1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0066cae2-e20b-41a9-812c-dda4d7ceb9f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2251, 0.0520, 0.4198, 0.9626],\n",
       "        [0.6625, 0.9449, 0.7348, 0.0224],\n",
       "        [0.5091, 0.1622, 0.8119, 0.4414]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random tensors\n",
    "#create a random tensor of shape 3,4\n",
    "\n",
    "random_tensor = torch.rand(3,4)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7117771a-c023-4392-a323-57729970775f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4fd74ba-e2cd-4b9e-b3b0-36d1d27b0a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34ec82d5-9627-41c1-a5cb-98315a68ccf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1925, 0.4335, 0.0672],\n",
       "         [0.4154, 0.4003, 0.4404],\n",
       "         [0.8732, 0.1908, 0.0560],\n",
       "         ...,\n",
       "         [0.4910, 0.5246, 0.7876],\n",
       "         [0.9963, 0.5591, 0.2294],\n",
       "         [0.3516, 0.2170, 0.9601]],\n",
       "\n",
       "        [[0.4772, 0.0126, 0.6339],\n",
       "         [0.9892, 0.4084, 0.7332],\n",
       "         [0.4730, 0.6231, 0.6061],\n",
       "         ...,\n",
       "         [0.8670, 0.1150, 0.9868],\n",
       "         [0.0859, 0.9058, 0.0049],\n",
       "         [0.4433, 0.3008, 0.8480]],\n",
       "\n",
       "        [[0.8357, 0.3986, 0.4340],\n",
       "         [0.4359, 0.4729, 0.8206],\n",
       "         [0.3649, 0.5016, 0.4900],\n",
       "         ...,\n",
       "         [0.7926, 0.5232, 0.9523],\n",
       "         [0.9782, 0.0657, 0.4206],\n",
       "         [0.2674, 0.0526, 0.5654]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.9664, 0.4910, 0.9833],\n",
       "         [0.5039, 0.2942, 0.2272],\n",
       "         [0.4408, 0.9498, 0.8955],\n",
       "         ...,\n",
       "         [0.6025, 0.6208, 0.5209],\n",
       "         [0.3356, 0.4601, 0.5073],\n",
       "         [0.4899, 0.6263, 0.7963]],\n",
       "\n",
       "        [[0.9050, 0.7128, 0.7718],\n",
       "         [0.9213, 0.9056, 0.3137],\n",
       "         [0.5818, 0.8981, 0.1014],\n",
       "         ...,\n",
       "         [0.7881, 0.5332, 0.8595],\n",
       "         [0.6500, 0.4974, 0.8757],\n",
       "         [0.7021, 0.6944, 0.5985]],\n",
       "\n",
       "        [[0.7869, 0.7705, 0.8225],\n",
       "         [0.7651, 0.5848, 0.6253],\n",
       "         [0.3638, 0.8779, 0.8213],\n",
       "         ...,\n",
       "         [0.5011, 0.5182, 0.1919],\n",
       "         [0.7472, 0.0787, 0.8088],\n",
       "         [0.2288, 0.1350, 0.3397]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a random tensor with similar shape to an image tensor.\n",
    "ran_image_size_tensor = torch.rand(size= (244, 244, 3)) #heigh, width, colour channels (r,g,b)\n",
    "ran_image_size_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d26bff6-be15-46cb-8a8a-49081f20165c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([244, 244, 3]), 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ran_image_size_tensor.shape, ran_image_size_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14febf3c-e7ed-4ac7-bad8-0bcb076077af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor of all zeros\n",
    "\n",
    "zeros = torch.zeros(3,4)\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "862e3043-44cb-4433-bf6f-176673dd1d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor of all ones\n",
    "\n",
    "ones = torch.ones(3,4)\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd0bde8f-3a9d-4557-bf48-cb69ab3b6a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9497072b-6476-4dac-9c94-9020595e3bf1",
   "metadata": {},
   "source": [
    "# Creating a range of tensors and tensor-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef3e39f1-479b-4fd2-8925-5ac8ddf85995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.1+cu102'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06012b67-2286-48cb-945f-afb3e36b07e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75/2132275013.py:2: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  torch.range(0,10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can use torch.range...\n",
    "torch.range(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17554786-08ef-4c37-b0d9-5ab1bc3fd99f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# But if we are working on a futere version of torch like 1.10 >\n",
    "# Then is probably better to use torch.arange.\n",
    "torch.arange(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "88aeb140-69b3-43e5-a51b-e2871634c995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2,  4,  6,  8, 10, 12, 14])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.arange use a segmentation like this: (Start, stop, step)\n",
    "torch.arange(2,15,2)\n",
    "# We start the sequeence at 2 and take steps of 2 until we finish in 14.\n",
    "# We put 15 instead of 14 because arange ends in n-1 like we show ahead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "626a04ca-41be-4c72-b5ef-ea8565262584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_to_n = torch.arange(1,14)\n",
    "one_to_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "55c28ba8-a0c8-4ea6-a07a-2437f1bf0f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Tensors like\n",
    "# given a previous shape\n",
    "one_to_n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "60402f0c-33ea-4513-b599-205992774be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we can create a new tensor with the same shape or size but with, for example. zeros\n",
    "zeros_like = torch.zeros_like(one_to_n)\n",
    "zeros_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "565fbf6a-0fa7-438e-94cb-a59105b8a4f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros_like.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f0835c6b-00c8-4c6e-b0e5-2512d0080ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.0000, 5.8000, 3.9000])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# float 32 tensor\n",
    "float_32t = torch.tensor([3.0, 5.8, 3.9],\n",
    "                        dtype = None, # What data type is the tensor (float32, float16...)\n",
    "                        device = None, # What device is your tensor using (None, GPU)\n",
    "                        requires_grad = False) # Whether or not to track gradients with this tensor operations.\n",
    "float_32t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "54a099cd-86f8-4fc7-9e7e-6960d3972d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32t.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ed93e98d-cdfc-4099-9a99-ba79b576d655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.0000, 5.8008, 3.9004], dtype=torch.float16)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16t = float_32t.type(torch.float16)\n",
    "float_16t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2406447d-b96b-4d11-a322-13f26a2cbae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16t.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4d0e0763-0543-43ab-969f-a9fac9f86dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.0000, 5.8008, 3.9004], dtype=torch.float16)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16t = float_32t.type(torch.half)\n",
    "float_16t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3369b2a1-6c30-4eb8-99ce-f55b8bfb88e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16t.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3226bf3f-bb8a-4a62-abb9-ff4659888bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9], dtype=torch.int32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32t = torch.tensor([3,6,9],\n",
    "                      dtype = torch.int32)\n",
    "int_32t "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9369a105-fb56-41b5-abfe-c747dfabcba0",
   "metadata": {},
   "source": [
    "# Getting information from tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "417b9ff8-879c-4451-9532-53a31981e9ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int32"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Datatype\n",
    "int_32t.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2e1b9ed4-90c5-4b20-aad9-2127340b25e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape\n",
    "int_32t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "390f5f2d-199a-4615-bc41-f06703462ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the device\n",
    "int_32t.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c963a9-3511-4512-9d63-46499248c631",
   "metadata": {},
   "source": [
    "# Tensor manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320361a1-d72e-4dd7-8c3e-ae3ba712fa19",
   "metadata": {},
   "source": [
    "### Some tensor operations include:\n",
    "* Addition\n",
    "* Substraction\n",
    "* Multiplication (element - wise)\n",
    "* Division\n",
    "* Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8ef0d057-78dd-4118-a2fb-32b74f840250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6716, 0.0404, 0.7412],\n",
       "         [0.1600, 0.8772, 0.2594],\n",
       "         [0.4955, 0.2840, 0.6274]]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tensor1 = torch.rand(1,3,3)\n",
    "Tensor1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "edbc6374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.8946, 0.0401, 0.6796],\n",
       "         [0.6882, 0.4659, 0.6384],\n",
       "         [0.3754, 0.3801, 0.3611]]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tensor2 = torch.rand(1,3,3)\n",
    "Tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ef19bdbf-055f-4a81-97e9-59d2542eaa9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[10.6716, 10.0404, 10.7412],\n",
       "         [10.1600, 10.8772, 10.2594],\n",
       "         [10.4955, 10.2840, 10.6274]]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tensor1 + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f30feb69-9cc5-4c45-a68d-dfa05a30c9c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[10.6716, 10.0404, 10.7412],\n",
       "         [10.1600, 10.8772, 10.2594],\n",
       "         [10.4955, 10.2840, 10.6274]]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the torch buid in function to add\n",
    "torch.add(Tensor1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1fcf1bd9-c0c7-41f4-87d7-b3bbc9accd15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-9.3284, -9.9596, -9.2588],\n",
       "         [-9.8400, -9.1228, -9.7406],\n",
       "         [-9.5045, -9.7160, -9.3726]]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tensor1 - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "137348d0-b65b-4323-8b58-7aff268ef6f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[6.7164, 0.4037, 7.4120],\n",
       "         [1.6000, 8.7723, 2.5936],\n",
       "         [4.9548, 2.8396, 6.2742]]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tensor1 * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "430cb606-49cf-4cc4-9c82-7270a609fcc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[6.7164, 0.4037, 7.4120],\n",
       "         [1.6000, 8.7723, 2.5936],\n",
       "         [4.9548, 2.8396, 6.2742]]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making multiplication with the torch build in function\n",
    "torch.mul(Tensor1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f973e3e7-ee26-4233-ab2f-b96d9893dbfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9069, 0.3275, 0.7499],\n",
       "         [0.8442, 0.5137, 0.7624],\n",
       "         [0.8742, 0.3906, 0.7446]]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication or dot product\n",
    "torch.matmul(Tensor1, Tensor2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d263b3d6-2753-49ef-b52b-80db925348b8",
   "metadata": {},
   "source": [
    "### One of the rules of matrix multiplication is that the inner dimentrion must match as shown:\n",
    "* (3,2) @ (3,2) won't work\n",
    "* (3,2) @ (2,3) will work\n",
    "* (2,3) @ (3,2) will work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "22bb1fce-02b9-4f6f-bd15-533047c3a9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> This operation is correct...\n",
      "   torch.Size([3, 2]) @ torch.Size([2, 3])\n",
      "   returns: tensor([[0.3982, 0.2886, 0.4442],\n",
      "        [0.4151, 0.4346, 0.6185],\n",
      "        [0.9987, 0.9156, 1.3367]]) torch.Size([3, 3])\n",
      ">> This operation is correct...\n",
      "   torch.Size([2, 3]) @ torch.Size([3, 2])\n",
      "   returns: tensor([[0.3414, 0.6077],\n",
      "        [0.1152, 0.2295]]) torch.Size([2, 2])\n",
      ">> is operation\n",
      "   torch.Size([2, 3]) @ torch.Size([2, 3]) \n",
      "   !!!it  won't work\n"
     ]
    }
   ],
   "source": [
    "op1 = torch.rand(3,2)\n",
    "op2 = torch.rand(2,3)\n",
    "op3 = torch.rand(2,3)\n",
    "\n",
    "def try_mat_rule1(x, y):\n",
    "    try:\n",
    "        r = torch.matmul(x, y)\n",
    "        print(f\">> This operation is correct...\")\n",
    "        print(f\"   {x.shape} @ {y.shape}\")\n",
    "        print(f\"   returns: {r} {r.shape}\")\n",
    "    except:\n",
    "        print(f\">> is operation\")\n",
    "        print(f\"   {x.shape} @ {y.shape} \")\n",
    "        print(f\"   !!!it  won't work\")\n",
    "        \n",
    "try_mat_rule1(op1, op2)\n",
    "try_mat_rule1(op3, op1)\n",
    "try_mat_rule1(op2, op3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c75a9fe-41ef-4d9a-b7b1-41dc29106db0",
   "metadata": {},
   "source": [
    "### Second rule...\n",
    "The resulted matrix will have the shape of the outer dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fec4e6ba-8a2f-4732-b1c4-80309e051fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the **torch.Size([3, 2]) @ torch.Size([2, 3]) will result into **torch.Size([3, 3])\n",
      "the **torch.Size([2, 3]) @ torch.Size([3, 2]) will result into **torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(f\"the **{op1.shape} @ {op2.shape} will result into **{torch.matmul(op1,op2).shape}\")\n",
    "print(f\"the **{op3.shape} @ {op1.shape} will result into **{torch.matmul(op3,op1).shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806443ff-c7d8-46ac-9741-f759984faa9b",
   "metadata": {},
   "source": [
    "### Adjusting the shape of tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8f1b2fe3-efb8-4f3b-b586-803a9078facc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing with a tensor like:\n",
      "tensor([[0.0432, 0.4165],\n",
      "        [0.2828, 0.3745],\n",
      "        [0.4490, 0.9591]]) habvin a shape torch.Size([3, 2])\n",
      "We use the transpose funtion to altere the shape like this:\n",
      "tensor([[0.0432, 0.2828, 0.4490],\n",
      "        [0.4165, 0.3745, 0.9591]]), shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# We can manipulate the shape of the tensor using the method transpose\n",
    "\n",
    "print(f\"Initializing with a tensor like:\")\n",
    "print(f\"{op1} habvin a shape {op1.shape}\")\n",
    "\n",
    "op1T = op1.T\n",
    "\n",
    "print(f\"We use the transpose funtion to altere the shape like this:\")\n",
    "print(f\"{op1T}, shape: {op1T.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde383b6-05a0-4a32-91a5-6a8bb8669d35",
   "metadata": {},
   "source": [
    "### Tensor aggregation...\n",
    "min, max, mean, sum, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "82e26f5a-1ec1-4ff2-8026-10d8722bc3b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tensor3 = torch.arange(0, 100 ,10)\n",
    "Tensor3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a2badaa6-4838-48e1-95df-57d89435edd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(90), tensor(0), tensor(90))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding min, max\n",
    "torch.min(Tensor3), torch.max(Tensor3), Tensor3.min(), Tensor3.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9b329909-a100-4926-a3e3-ce6e7f036b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(45.), tensor(45.))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the mean\n",
    "# The above code launch an error because of the dtype.\n",
    "# We manage to solve this error by converting the original dtype from in 64 to float32 using the \"type\" function.\n",
    "torch.mean(Tensor3.type(torch.float32)), Tensor3.type(torch.float32).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7939a576-cf67-4454-b4bb-e0a6a9b84275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(450), tensor(450))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Findinf sum\n",
    "torch.sum(Tensor3), Tensor3.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56db905c-1913-4b00-962e-8ed665841af7",
   "metadata": {},
   "source": [
    "### Finding the positional min and max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "47049f0d-fbea-41d9-aba7-278634898ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(9))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tensor3.argmin(), Tensor3.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606d7484-6b8b-4767-8858-c76bba52a3ce",
   "metadata": {},
   "source": [
    "### Reshaping, Stacking, squeezing and un squeezing\n",
    "\n",
    "* Reshaping - Reshapes an input tensor to a defined shape\n",
    "* View - Return a view of an input tensor of certain shape but keep the same memory as the original tensor\n",
    "* Stacking - Conbine multiple tensors on top of each other (V-stack) or side by side (H-stack)\n",
    "\n",
    "* Squeeze - Removes all '1' dimension from a tensor\n",
    "* Unsqueeze - Add a '1' dimension to a target tensor\n",
    "* Permute - Return a view of the input with the dimensions permuted (swaped) in a certain way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3abecf-9ebd-4ac4-9cd8-d529f50ba807",
   "metadata": {},
   "source": [
    "**Reshape**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "99f12870-f81b-493a-ab4c-05aa8522b4b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90]), torch.Size([10]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Given a original vector\n",
    "Tensor3, Tensor3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b029a5b5-3150-4d2d-88d8-accd8396e18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Original:\n",
      " (torch.Size([10]), tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90]))\n",
      "\n",
      ">> Shape 1:\n",
      " (torch.Size([1, 10]), tensor([[ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90]]))\n",
      "\n",
      ">> Shape 2:\n",
      " (torch.Size([2, 5]), tensor([[ 0, 10, 20, 30, 40],\n",
      "        [50, 60, 70, 80, 90]]))\n",
      "\n",
      ">> shape 3:\n",
      " (torch.Size([5, 2]), tensor([[ 0, 10],\n",
      "        [20, 30],\n",
      "        [40, 50],\n",
      "        [60, 70],\n",
      "        [80, 90]]))\n",
      "\n",
      ">> shape 3:\n",
      " (torch.Size([10, 1]), tensor([[ 0],\n",
      "        [10],\n",
      "        [20],\n",
      "        [30],\n",
      "        [40],\n",
      "        [50],\n",
      "        [60],\n",
      "        [70],\n",
      "        [80],\n",
      "        [90]]))\n"
     ]
    }
   ],
   "source": [
    "# we can reshape the given tensro above for other shape that match the number size that it already has like so:\n",
    "print(f\">> Original:\\n {Tensor3.shape , Tensor3}\\n\")\n",
    "print(f\">> Shape 1:\\n {Tensor3.reshape(1,10).shape , Tensor3.reshape(1,10)}\\n\")\n",
    "print(f\">> Shape 2:\\n {Tensor3.reshape(2,5).shape, Tensor3.reshape(2,5)}\\n\")\n",
    "print(f\">> shape 3:\\n {Tensor3.reshape(5,2).shape, Tensor3.reshape(5,2)}\\n\")\n",
    "print(f\">> shape 3:\\n {Tensor3.reshape(10,1).shape, Tensor3.reshape(10,1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9830fd-80de-4869-95c0-c455593722d9",
   "metadata": {},
   "source": [
    "**View**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "16d5b492-6dc3-488d-866d-2b5cc50db6a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# changing view...\n",
    "x = torch.arange(1, 15)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6fbe6753-1782-4542-a88a-656ef703249c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z = tensor([[ 1,  2,  3,  4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11, 12, 13, 14]])\n",
      "x = tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])\n"
     ]
    }
   ],
   "source": [
    "# The function view share the same sapace memory with the original tensor\n",
    "z = x.view(2,7)\n",
    "print(f\"z = {z}\\nx = {x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4519fcf4-b857-49b6-9be8-9c1a5d2617d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z = tensor([[ 6,  2,  3,  4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11, 12, 13, 14]])\n",
      "x = tensor([ 6,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])\n"
     ]
    }
   ],
   "source": [
    "# Thus, if we change a tensor made with the view function, this will change the original and vice versa\n",
    "# Here we changed the first number of the first dimension of the z tensor to 6...\n",
    "# and now we see how the first number of the x tensor change to 6 too but everything else stays the equal\n",
    "z[0][0]= 6\n",
    "print(f\"z = {z}\\nx = {x}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64451767-f90f-4fd4-a5c7-aebc6a573261",
   "metadata": {},
   "source": [
    "**Stacking**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7d958737-3c19-4dde-a32f-424840c5b800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 6,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14],\n",
       "         [ 6,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14],\n",
       "         [ 6,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14],\n",
       "         [ 6,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]]),\n",
       " tensor([[ 6,  6,  6,  6],\n",
       "         [ 2,  2,  2,  2],\n",
       "         [ 3,  3,  3,  3],\n",
       "         [ 4,  4,  4,  4],\n",
       "         [ 5,  5,  5,  5],\n",
       "         [ 6,  6,  6,  6],\n",
       "         [ 7,  7,  7,  7],\n",
       "         [ 8,  8,  8,  8],\n",
       "         [ 9,  9,  9,  9],\n",
       "         [10, 10, 10, 10],\n",
       "         [11, 11, 11, 11],\n",
       "         [12, 12, 12, 12],\n",
       "         [13, 13, 13, 13],\n",
       "         [14, 14, 14, 14]]),\n",
       " tensor([[ 6,  6,  6,  6],\n",
       "         [ 2,  2,  2,  2],\n",
       "         [ 3,  3,  3,  3],\n",
       "         [ 4,  4,  4,  4],\n",
       "         [ 5,  5,  5,  5],\n",
       "         [ 6,  6,  6,  6],\n",
       "         [ 7,  7,  7,  7],\n",
       "         [ 8,  8,  8,  8],\n",
       "         [ 9,  9,  9,  9],\n",
       "         [10, 10, 10, 10],\n",
       "         [11, 11, 11, 11],\n",
       "         [12, 12, 12, 12],\n",
       "         [13, 13, 13, 13],\n",
       "         [14, 14, 14, 14]]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack tensors on top of each other depending on the number of dimensions\n",
    "# The dimension number must be compatuble with the original tensor.\n",
    "stacked1 = torch.stack([x,x,x,x], dim= 0) # 0 is the dim by default\n",
    "stacked2 = torch.stack([x,x,x,x], dim= 1)\n",
    "stacked3 = torch.stack([x,x,x,x], dim= -2)\n",
    "\n",
    "stacked1, stacked2, stacked2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee34093b-edb2-4d36-9539-efc2f7492852",
   "metadata": {},
   "source": [
    "### Squeezing, unsqueezing and permuting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854f9185-16e2-4155-9ef2-6485fd4a5419",
   "metadata": {},
   "source": [
    "**Squeeze**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dc1d5532-9b2f-4589-81c6-212f9a2c7f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> For a shape like squeeze 1\n",
      "\n",
      ">>>torch.Size([1, 1, 14])\n",
      "\n",
      "  tensor([[[0.8709, 0.8169, 0.7628, 0.5075, 0.5160, 0.1089, 0.7252, 0.8997,\n",
      "          0.0814, 0.8737, 0.4666, 0.7984, 0.3785, 0.4659]]])\n",
      "\n",
      ">>>torch.Size([14])\n",
      "\n",
      "   tensor([0.8709, 0.8169, 0.7628, 0.5075, 0.5160, 0.1089, 0.7252, 0.8997, 0.0814,\n",
      "        0.8737, 0.4666, 0.7984, 0.3785, 0.4659])\n",
      "\n",
      "\n",
      ">> for a shape like squeeze 2\n",
      "\n",
      ">>>torch.Size([1, 2, 14])\n",
      "\n",
      "  tensor([[[0.0875, 0.3282, 0.3598, 0.2993, 0.1835, 0.9528, 0.3887, 0.2110,\n",
      "          0.4972, 0.0756, 0.3862, 0.7653, 0.8464, 0.8506],\n",
      "         [0.4223, 0.7153, 0.2635, 0.4358, 0.8811, 0.9066, 0.3045, 0.1476,\n",
      "          0.3709, 0.1692, 0.6263, 0.6256, 0.0383, 0.2908]]])\n",
      "\n",
      ">>>torch.Size([2, 14])\n",
      "\n",
      "   tensor([[0.0875, 0.3282, 0.3598, 0.2993, 0.1835, 0.9528, 0.3887, 0.2110, 0.4972,\n",
      "         0.0756, 0.3862, 0.7653, 0.8464, 0.8506],\n",
      "        [0.4223, 0.7153, 0.2635, 0.4358, 0.8811, 0.9066, 0.3045, 0.1476, 0.3709,\n",
      "         0.1692, 0.6263, 0.6256, 0.0383, 0.2908]])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# squeeze = tensor.squeeze\n",
    "forsuqeeze1 = torch.rand(1,1,14)\n",
    "forsuqeeze2 = torch.rand(1,2,14)\n",
    "print(f\">> For a shape like squeeze 1\\n\\n>>>{forsuqeeze1.shape}\\n\\n  {forsuqeeze1}\\n\\n>>>{forsuqeeze1.squeeze().shape}\\n\\n   {forsuqeeze1.squeeze()}\\n\\n\")\n",
    "print(f\">> for a shape like squeeze 2\\n\\n>>>{forsuqeeze2.shape}\\n\\n  {forsuqeeze2}\\n\\n>>>{forsuqeeze2.squeeze().shape}\\n\\n   {forsuqeeze2.squeeze()}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2e94e5-18bb-4eaa-9954-e5ec750290f1",
   "metadata": {},
   "source": [
    "**Unsqueeze**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1e37d23a-4d29-4fb7-9912-a64bb176d09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> For a shape like squeeze 1\n",
      "\n",
      ">>>torch.Size([1, 1, 14])\n",
      "\n",
      "  tensor([[[[0.8709, 0.8169, 0.7628, 0.5075, 0.5160, 0.1089, 0.7252, 0.8997,\n",
      "           0.0814, 0.8737, 0.4666, 0.7984, 0.3785, 0.4659]]]])\n",
      "\n",
      "\n",
      ">> for a shape like squeeze 2\n",
      "\n",
      ">>>torch.Size([1, 2, 14])\n",
      "\n",
      "  tensor([[[0.0875, 0.3282, 0.3598, 0.2993, 0.1835, 0.9528, 0.3887, 0.2110,\n",
      "          0.4972, 0.0756, 0.3862, 0.7653, 0.8464, 0.8506],\n",
      "         [0.4223, 0.7153, 0.2635, 0.4358, 0.8811, 0.9066, 0.3045, 0.1476,\n",
      "          0.3709, 0.1692, 0.6263, 0.6256, 0.0383, 0.2908]]])\n",
      "\n",
      " dim=1 pos=[1]... \n",
      ">>>torch.Size([1, 1, 2, 14])\n",
      "\n",
      " dim=2 pos=[2]... \n",
      ">>>torch.Size([1, 2, 1, 14])\n",
      "\n",
      " dim=3 pos=[3]... \n",
      ">>>torch.Size([1, 2, 14, 1])\n",
      "\n",
      "   tensor([[[[0.0875],\n",
      "          [0.3282],\n",
      "          [0.3598],\n",
      "          [0.2993],\n",
      "          [0.1835],\n",
      "          [0.9528],\n",
      "          [0.3887],\n",
      "          [0.2110],\n",
      "          [0.4972],\n",
      "          [0.0756],\n",
      "          [0.3862],\n",
      "          [0.7653],\n",
      "          [0.8464],\n",
      "          [0.8506]],\n",
      "\n",
      "         [[0.4223],\n",
      "          [0.7153],\n",
      "          [0.2635],\n",
      "          [0.4358],\n",
      "          [0.8811],\n",
      "          [0.9066],\n",
      "          [0.3045],\n",
      "          [0.1476],\n",
      "          [0.3709],\n",
      "          [0.1692],\n",
      "          [0.6263],\n",
      "          [0.6256],\n",
      "          [0.0383],\n",
      "          [0.2908]]]])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unsqueeze = tensor.unsqueeze\n",
    "print(f\">> For a shape like squeeze 1\\n\\n>>>{forsuqeeze1.shape}\\n\\n  {forsuqeeze1.unsqueeze(dim=1)}\\n\\n\")\n",
    "print(f\">> for a shape like squeeze 2\\n\\n>>>{forsuqeeze2.shape}\\n\\n  {forsuqeeze2}\\n\\n dim=1 pos=[1]... \\n>>>{forsuqeeze2.unsqueeze(dim=1).shape}\\n\\n dim=2 pos=[2]... \\n>>>{forsuqeeze2.unsqueeze(dim=2).shape}\\n\\n dim=3 pos=[3]... \\n>>>{forsuqeeze2.unsqueeze(dim=3).shape}\\n\\n   {forsuqeeze2.unsqueeze(dim=3)}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befa34f2-d8fb-403d-b23f-9b3a5c7d9c9d",
   "metadata": {},
   "source": [
    "**Permute**\\\n",
    "Rearange the target dimensions on a specified order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7e6429b4-571c-4b7c-82ba-f5efd9b043be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original =\n",
      "   >> torch.Size([255, 255, 3])\n",
      "\n",
      "Permuted =\n",
      "   >> torch.Size([3, 255, 255])\n"
     ]
    }
   ],
   "source": [
    "# torch.permute()\n",
    "# The permute function share the same space in memory so if we what ever tensor assosiated with the permute Function\n",
    "# it will be change on all the tensors associated\n",
    "x1 = torch.rand(255, 255, 3) # [height, width, colour_channels] -> (a commond representation of image data)\n",
    "\n",
    "# Permute x1 to rearange in the order [colour_channels, height, width]\n",
    "x1_perm= x1.permute(2, 0, 1)\n",
    "print(f\"\\nOriginal =\\n   >> {x1.shape}\\n\\nPermuted =\\n   >> {x1_perm.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede46b0a-c2a4-465c-84e5-377903525360",
   "metadata": {},
   "source": [
    "### Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "34443472-0795-4c8f-9ee4-6f43fcc279c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 3,  6,  9],\n",
       "          [12, 15, 18],\n",
       "          [21, 24, 27]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Given an original tensor...\n",
    "x2= torch.arange(3,28,3).reshape(1,3,3)\n",
    "x2 , x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "af014df5-d237-48b3-9379-fdce76ed8172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: \n",
      ">>> tensor([[[ 3,  6,  9],\n",
      "         [12, 15, 18],\n",
      "         [21, 24, 27]]])\n",
      "\n",
      "\n",
      "First index x2[0]: \n",
      ">>> tensor([[ 3,  6,  9],\n",
      "        [12, 15, 18],\n",
      "        [21, 24, 27]])\n",
      "\n",
      "\n",
      "First index and second index inside of it x2[0][1]>>> \n",
      ">>> tensor([12, 15, 18])\n",
      "\n",
      "\n",
      "->[Alternative] Same as the last one but with a different method x2[0,1]: \n",
      "  >>> tensor([12, 15, 18])\n",
      "\n",
      "\n",
      "Third number inside the second line of the first index x2[0][1][2]: \n",
      ">>> 18\n",
      "\n",
      "\n",
      "->[Alternative] Same as the last one but with a different method x2[0,1,2]: \n",
      "  >>> 18\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now we index the tensor\n",
    "print(f\"Original: \\n>>> {x2}\\n\\n\")\n",
    "print(f\"First index x2[0]: \\n>>> {x2[0]}\\n\\n\")\n",
    "print(f\"First index and second index inside of it x2[0][1]>>> \\n>>> {x2[0][1]}\\n\\n\")\n",
    "print(f\"->[Alternative] Same as the last one but with a different method x2[0,1]: \\n  >>> {x2[0,1]}\\n\\n\")\n",
    "print(f\"Third number inside the second line of the first index x2[0][1][2]: \\n>>> {x2[0][1][2]}\\n\\n\")\n",
    "print(f\"->[Alternative] Same as the last one but with a different method x2[0,1,2]: \\n  >>> {x2[0,1,2]}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d848bdf8-76f2-4947-b3ed-e19fdda7acfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12, 15, 18]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can algo use the ':' to select all items from a target dimension\n",
    "x2[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f5e44e77-3d38-45c4-b381-93b810f4f32e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 3,  6,  9],\n",
       "          [12, 15, 18],\n",
       "          [21, 24, 27]]]),\n",
       " tensor([[ 6, 15, 24]]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting all elements of the and second dimension but only the second element of the third dimension\n",
    "# Graphic explaination >>> totch.size([n, n, n]) we mark with \"Xpos\" our target >>> torch.size([:, :, X2])\n",
    "# Now in matrix format >>> tensor([[ n, X, n],\n",
    "#                                  [ n, X, n],\n",
    "#                                  [ n, X, n]])\n",
    "x2, x2[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "316192f8-0476-49fe-b38e-5b14942aaa9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 3,  6,  9],\n",
       "          [12, 15, 18],\n",
       "          [21, 24, 27]]]),\n",
       " tensor([15]),\n",
       " tensor(15))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A little diffenrence to having in mind about the indexing with ':'\n",
    "# If we put the ':' at the beguinig, it returns us the first dimention of the tensor with the desired one\n",
    "# If we dont put the ':' but the dimension itself, it returns us only the desired dimension\n",
    "x2, x2[:,1,1], x2[0,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "188c044d-1157-4cbb-9dfc-b3f680c8b1cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 3,  6,  9],\n",
       "          [12, 15, 18],\n",
       "          [21, 24, 27]]]),\n",
       " tensor([21, 24, 27]),\n",
       " tensor([21, 24, 27]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we put the ':' at last it returns only all the elements of the last dimension\n",
    "x2, x2[0,2,:], x2[0,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44731f8e-432f-4868-944e-116b96f281bb",
   "metadata": {},
   "source": [
    "# Pytorch tensors and NumPy\n",
    "Due that Pytorch have dependencies and integration with NumPy we will possibly need to use this Python library in somo of our work. That is why we'll have in mind that the data in NumPy has it's own type, \"ndaarray\", and we will probbably need to convert it to a Tensor type to process it with torch.\n",
    "we can use \"**torch.from_numpy(ndarray)**\" to pass it from NumPy type to tensor and \"**torch.tensor.numpy()**\" from tensor to NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1d28a1c6-cf18-43ad-82c5-f231ee1aa7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type narray=\n",
      "<class 'numpy.ndarray'>\n",
      " [ 2.  5.  8. 11. 14. 17. 20. 23. 26. 29. 32. 35. 38. 41.]\n",
      "\n",
      "Type ntensor=\n",
      "<class 'torch.Tensor'>\n",
      " tensor([ 2.,  5.,  8., 11., 14., 17., 20., 23., 26., 29., 32., 35., 38., 41.],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Numpy to Tensor\n",
    "narray = np.arange(2.0, 42.0, 3.0)\n",
    "ntensor = torch.from_numpy(narray)\n",
    "print(f\"Type narray=\\n{type(narray)}\\n {narray}\\n\\nType ntensor=\\n{type(ntensor)}\\n {ntensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5fc5015c-f201-41f7-b9d7-4e6c589d4fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy dtype = \n",
      " float64\n",
      "\n",
      "Pytorch dtype = \n",
      " torch.float32\n"
     ]
    }
   ],
   "source": [
    "# We need to have in mind that both, NumPy and Pytorch, create a different dtype by default\n",
    "# Numpy create a float-64 and Pytorch a float-32 as shown afete:\n",
    "print(f\"NumPy dtype = \\n {np.arange(0.0,10.0).dtype}\\n\\nPytorch dtype = \\n {torch.arange(0.0,10.0).dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "33261f81-afca-4970-9264-1fbff7226d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type ntensor=\n",
      "<class 'torch.Tensor'>\n",
      " tensor([20., 21., 22., 23., 24., 25., 26., 27., 28., 29.])\n",
      "\n",
      "Type narray=\n",
      "<class 'numpy.ndarray'>\n",
      " [20. 21. 22. 23. 24. 25. 26. 27. 28. 29.]\n"
     ]
    }
   ],
   "source": [
    "# From tensor to NumPy\n",
    "ntensor = torch.arange(20.0,30.0)\n",
    "narray = ntensor.numpy()\n",
    "print(f\"Type ntensor=\\n{type(ntensor)}\\n {ntensor}\\n\\nType narray=\\n{type(narray)}\\n {narray}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbf221f-09a0-4894-856b-757b4192694a",
   "metadata": {},
   "source": [
    "## Reproducibility (Trying to take random out of random)\n",
    "We use a random seed to reduce a bit the randomness of our values or experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c5a077fd-1ec1-4514-9a1b-eb94c503d994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.1182, 0.4387, 0.8180],\n",
       "         [0.0982, 0.0503, 0.7128],\n",
       "         [0.8284, 0.1884, 0.1025]]),\n",
       " tensor([[0.8272, 0.3180, 0.4504],\n",
       "         [0.1100, 0.3681, 0.0187],\n",
       "         [0.9573, 0.3108, 0.5141]]),\n",
       " tensor([[0.7260, 0.5707, 0.3254],\n",
       "         [0.2919, 0.8707, 0.3518],\n",
       "         [0.8129, 0.2901, 0.6826]]))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Everytime we run this cell, we will find that the output is different\n",
    "torch.rand(3,3), torch.rand(3,3), torch.rand(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "164e9e0b-fd9c-41fa-930c-247586232086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8823, 0.9150, 0.3829],\n",
       "        [0.9593, 0.3904, 0.6009],\n",
       "        [0.2566, 0.7936, 0.9408]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we use a random seed to minimize a little that randomness of the begining so we can work with\n",
    "# a little bit more predictable numbers, that allow us to reproduce somehow the results we are achieving\n",
    "# here in other processes\n",
    "# First we use a number as random seed, generaly 42 or somewher arond\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.rand(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "785baf89-0307-4bff-8be5-042a1340a05d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8823, 0.9150, 0.3829],\n",
       "        [0.9593, 0.3904, 0.6009],\n",
       "        [0.2566, 0.7936, 0.9408]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we see that our seed is replicating the results we get before, making the beheabore of our randomness\n",
    "# so much more predictable thus we can get similar results and iterate more easily the process\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.rand(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5a64eb0b-b247-4578-90f5-55e891562b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1332, 0.9346, 0.5936],\n",
       "        [0.8694, 0.5677, 0.7411],\n",
       "        [0.4294, 0.8854, 0.5739]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to have in mind that the RANDOM_SEED just works for one line of code \n",
    "torch.rand(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "189cac10-c2bf-474f-9020-9ea748778f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8823, 0.9150, 0.3829],\n",
       "        [0.9593, 0.3904, 0.6009],\n",
       "        [0.2566, 0.7936, 0.9408]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so if we want to use it again we will need to call it again\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.rand(3,3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
